{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUCBV Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "class BanditAlgorithm:\n",
    "    \"\"\"\n",
    "    A class to represent a bandit algorithm and manage its results.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    name : str\n",
    "        The name of the bandit algorithm.\n",
    "    results : list\n",
    "        A list to store results of the algorithm's performance over iterations.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count):\n",
    "        self.results.append([param, iteration, total_reward, suboptimal_arms_count, round(total_regret, 2), zeros_count, ones_count])\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        avg_results = {}\n",
    "        for result in self.results:\n",
    "            param = result[0]\n",
    "            if param not in avg_results:\n",
    "                avg_results[param] = [0, 0, 0, 0, 0]\n",
    "            avg_results[param][0] += result[2]  # Total Reward\n",
    "            avg_results[param][1] += result[3]  # Suboptimal Arms Count\n",
    "            avg_results[param][2] += result[4]  # Total Regret\n",
    "            avg_results[param][3] += result[5]  # Zeros Count\n",
    "            avg_results[param][4] += result[6]  # Ones Count\n",
    "        \n",
    "        for param in avg_results:\n",
    "            avg_results[param] = [param] + [x / 100 for x in avg_results[param]]\n",
    "        return list(avg_results.values())\n",
    "\n",
    "def EUCBV_simulation(arm_means, total_steps):\n",
    "    \"\"\"\n",
    "    Simulates the epsilon-greedy algorithm over given time horizons.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    arm_means : in\n",
    "        The arm_means array.\n",
    "    total_steps : list\n",
    "        A list of time horizons at which to record the results.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary where keys are time horizons and values are tuples of (total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count).\n",
    "    \"\"\"\n",
    "    K = len(arm_means)\n",
    "    rho = 1 / 2\n",
    "    psi = total_steps / (K**2)\n",
    "    \n",
    "    T_k = np.zeros(K)  # Number of times each arm has been played\n",
    "    X_k = np.zeros(K)  # Sum of rewards for each arm\n",
    "    sum_of_squares = np.zeros(K)  # Sum of squared differences for each arm\n",
    "    \n",
    "    zeros_count = 0\n",
    "    ones_count = 0\n",
    "    \n",
    "    B_t = set(range(K))\n",
    "    delta_t = 1\n",
    "    total_reward = 0\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    \n",
    "    regret = np.zeros(total_steps)\n",
    "    suboptimal_arms = np.zeros(total_steps, dtype=int)\n",
    "    total_rewards = np.zeros(total_steps)\n",
    "    zeros_counts = np.zeros(total_steps, dtype=int)\n",
    "    ones_counts = np.zeros(total_steps, dtype=int)\n",
    "\n",
    "    def play_arm(arm, t):\n",
    "        nonlocal zeros_count, ones_count, total_reward, suboptimal_arms_count, total_regret\n",
    "        reward = np.random.binomial(1, arm_means[arm])\n",
    "        T_k[arm] += 1\n",
    "        X_k[arm] += reward\n",
    "        sum_of_squares[arm] += reward**2\n",
    "        total_reward += reward\n",
    "        \n",
    "        if reward == 0:\n",
    "            zeros_count += 1\n",
    "        else:\n",
    "            ones_count += 1\n",
    "        \n",
    "        if arm != np.argmax(arm_means):\n",
    "            suboptimal_arms_count += 1\n",
    "            total_regret += np.max(arm_means) - arm_means[arm]\n",
    "\n",
    "        total_rewards[t] = total_reward\n",
    "        regret[t] = total_regret\n",
    "        suboptimal_arms[t] = suboptimal_arms_count\n",
    "        zeros_counts[t] = zeros_count\n",
    "        ones_counts[t] = ones_count\n",
    "        \n",
    "        return reward\n",
    "\n",
    "    for arm in range(K):\n",
    "        play_arm(arm, arm)\n",
    "    \n",
    "    M = int(math.floor(0.5 * math.log2(total_steps / math.exp(1))))\n",
    "    m = 0\n",
    "    n_0 = int(math.ceil(math.log(psi * total_steps * delta_t**2) / (2 * delta_t)))\n",
    "    N_0 = K * n_0\n",
    "    \n",
    "    for t in range(K, total_steps):\n",
    "        if len(B_t) == 1:\n",
    "            best_arm = next(iter(B_t))\n",
    "            play_arm(best_arm, t)\n",
    "            continue\n",
    "        \n",
    "        selected_arm = max(B_t, key=lambda arm_index: (X_k[arm_index] / T_k[arm_index]) + math.sqrt((rho * ((sum_of_squares[arm_index] / T_k[arm_index]) - (X_k[arm_index] / T_k[arm_index])**2 + 2) * math.log(psi * total_steps * delta_t)) / (4 * T_k[arm_index])))\n",
    "        play_arm(selected_arm, t)\n",
    "        \n",
    "        for arm_index in list(B_t):\n",
    "            mean_estimate = X_k[arm_index] / T_k[arm_index]\n",
    "            variance_estimate = (sum_of_squares[arm_index] - T_k[arm_index] * (mean_estimate ** 2)) / T_k[arm_index]\n",
    "            bound = math.sqrt((rho * (variance_estimate + 2) * math.log(psi * total_steps * delta_t)) / (4 * T_k[arm_index]))\n",
    "            \n",
    "            for k in range(K):\n",
    "                mean_reward = X_k[k] / T_k[k]\n",
    "                EUCBV = mean_reward - math.sqrt((rho * ((sum_of_squares[k] / T_k[k]) - (X_k[k] / T_k[k])**2 + 2) * math.log(psi * total_steps * delta_t)) / (4 * T_k[k]))\n",
    "            maximum = np.max(EUCBV)\n",
    "\n",
    "            if mean_estimate + bound < maximum:\n",
    "                B_t.remove(arm_index)\n",
    "        \n",
    "        if t >= N_0 and m <= M:\n",
    "            delta_t /= 2\n",
    "            B_t = B_t\n",
    "            n_0 = int(math.ceil(math.log(psi * total_steps * delta_t**2) / (2 * delta_t)))\n",
    "            N_0 = t + len(B_t) * n_0\n",
    "            m += 1\n",
    "\n",
    "    return {\n",
    "        \"total_rewards\": total_rewards,\n",
    "        \"suboptimal_arms\": suboptimal_arms,\n",
    "        \"regret\": regret,\n",
    "        \"zeros_counts\": zeros_counts,\n",
    "        \"ones_counts\": ones_counts\n",
    "    }\n",
    "\n",
    "def general_simulation(algorithm, arm_means, parameters, strategy_fn):\n",
    "    \"\"\"\n",
    "    Runs a general simulation for the specified bandit algorithm over given parameters and arm means using a provided simulation function.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    parameters : list\n",
    "        A list of parameters (timesteps) for which to record the results.\n",
    "    arm_means : numpy.ndarray\n",
    "        The true means of each arm.\n",
    "    simulation_func : function\n",
    "        The simulation function to run for the algorithm. This function should accept the same parameters as ETC_simulation and return results in a similar format.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    max_time_horizon = max(parameters)\n",
    "    num_arms = len(arm_means)\n",
    "\n",
    "    for iteration in range(1, 101):\n",
    "        results = strategy_fn(arm_means, max_time_horizon)\n",
    "\n",
    "        for param in parameters:\n",
    "            total_reward = results[\"total_rewards\"][param - 1]\n",
    "            suboptimal_arms_count = results[\"suboptimal_arms\"][param - 1]\n",
    "            total_regret = results[\"regret\"][param - 1]\n",
    "            zeros_count = results[\"zeros_counts\"][param - 1]\n",
    "            ones_count = results[\"ones_counts\"][param - 1]\n",
    "\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n",
    "\n",
    "\n",
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"9_EUCBV\"),\n",
    "]\n",
    "\n",
    "\n",
    "arm_means = np.array([0.495, 0.5])\n",
    "\n",
    "# Perform simulation and save results\n",
    "results_path = r'C:/Users/canis/OneDrive\\Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "for algorithm in algorithms:\n",
    "    general_simulation(algorithm, arm_means, time_horizons, EUCBV_simulation)\n",
    "    algorithm.save_results_to_csv(f'{results_path}\\{algorithm.name}_results_subopt_ver3.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}\\{algorithm.name}_average_results_subopt_ver3.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
