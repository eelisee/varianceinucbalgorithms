{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB-Improved Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "class BanditAlgorithm:\n",
    "    \"\"\"\n",
    "    A class to represent a bandit algorithm and manage its results.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    name : str\n",
    "        The name of the bandit algorithm.\n",
    "    results : list\n",
    "        A list to store results of the algorithm's performance over iterations.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count):\n",
    "        self.results.append([param, iteration, total_reward, suboptimal_arms_count, round(total_regret, 2), zeros_count, ones_count])\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        avg_results = {}\n",
    "        for result in self.results:\n",
    "            param = result[0]\n",
    "            if param not in avg_results:\n",
    "                avg_results[param] = [0, 0, 0, 0, 0]\n",
    "            avg_results[param][0] += result[2]  # Total Reward\n",
    "            avg_results[param][1] += result[3]  # Suboptimal Arms Count\n",
    "            avg_results[param][2] += result[4]  # Total Regret\n",
    "            avg_results[param][3] += result[5]  # Zeros Count\n",
    "            avg_results[param][4] += result[6]  # Ones Count\n",
    "        \n",
    "        for param in avg_results:\n",
    "            avg_results[param] = [param] + [x / 100 for x in avg_results[param]]\n",
    "        return list(avg_results.values())\n",
    "\n",
    "def UCB_Improved_simulation(arm_means, total_steps):\n",
    "    \"\"\"\n",
    "    Simulates the UCB-Improved algorithm over given time horizons.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    arm_means : in\n",
    "        The arm_means array.\n",
    "    total_steps : list\n",
    "        A list of time horizons at which to record the results.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary where keys are time horizons and values are tuples of (total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count).\n",
    "    \"\"\"\n",
    "    num_arms = len(arm_means)\n",
    "    rewards = np.zeros(num_arms)\n",
    "    pulls = np.zeros(num_arms)\n",
    "    total_reward = 0\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    zeros_count = 0\n",
    "    ones_count = 0\n",
    "\n",
    "    delta = 1\n",
    "    B = list(range(num_arms))\n",
    "    UCB_Improved_max = np.zeros(num_arms)\n",
    "\n",
    "    first_phase_end = int(np.floor(0.5 * np.log2(total_steps / np.exp(1))))\n",
    "    \n",
    "    t = 0  # Phase variable\n",
    "    z = 0  # Time steps\n",
    "    \n",
    "    regret = np.zeros(total_steps)\n",
    "    suboptimal_arms = np.zeros(total_steps, dtype=int)\n",
    "    total_rewards = np.zeros(total_steps)\n",
    "    zeros_counts = np.zeros(total_steps, dtype=int)\n",
    "    ones_counts = np.zeros(total_steps, dtype=int)\n",
    "    \n",
    "    while z < total_steps:\n",
    "        if t < first_phase_end:\n",
    "            for m in B:\n",
    "                max_pulls = math.ceil((2 * np.log(total_steps * delta**2)) / delta**2)\n",
    "                if pulls[m] <= max_pulls:\n",
    "                    reward = np.random.binomial(1, arm_means[m])\n",
    "                    rewards[m] += reward\n",
    "                    pulls[m] += 1\n",
    "                    total_reward += reward\n",
    "                    total_regret += np.max(arm_means) - arm_means[m]\n",
    "                    if reward == 0:\n",
    "                        zeros_count += 1\n",
    "                    else:\n",
    "                        ones_count += 1\n",
    "                    if m != np.argmax(arm_means):\n",
    "                        suboptimal_arms_count += 1\n",
    "                    z += 1  # Increase the time step after each pull\n",
    "                    total_rewards[z - 1] = total_reward\n",
    "                    regret[z - 1] = total_regret\n",
    "                    suboptimal_arms[z - 1] = suboptimal_arms_count\n",
    "                    zeros_counts[z - 1] = zeros_count\n",
    "                    ones_counts[z - 1] = ones_count\n",
    "                    if z >= total_steps:\n",
    "                        break\n",
    "            \n",
    "            if z < total_steps:  # Only eliminate if time remains\n",
    "                UCB_Improved_max = max((rewards[j] / pulls[j]) - np.sqrt((np.log(total_steps * delta**2)) / (2 * max_pulls)) for j in B)\n",
    "                B = [k for k in B if (rewards[k] / pulls[k]) + np.sqrt((np.log(total_steps * delta**2)) / (2 * max_pulls)) >= UCB_Improved_max]\n",
    "                delta /= 2\n",
    "                t += 1  # Move to the next phase\n",
    "        else:\n",
    "            # Second phase\n",
    "            if len(B) == 1:\n",
    "                best_arm = B[0]\n",
    "            else:\n",
    "                best_arm = max(B, key=lambda k: rewards[k] / pulls[k])\n",
    "            reward = np.random.binomial(1, arm_means[best_arm])\n",
    "            total_reward += reward\n",
    "            pulls[best_arm] += 1\n",
    "            total_regret += np.max(arm_means) - arm_means[best_arm]\n",
    "            if reward == 0:\n",
    "                zeros_count += 1\n",
    "            else:\n",
    "                ones_count += 1\n",
    "            if best_arm != np.argmax(arm_means):\n",
    "                suboptimal_arms_count += 1\n",
    "            z += 1  # Increase the time step after each pull\n",
    "            total_rewards[z - 1] = total_reward\n",
    "            regret[z - 1] = total_regret\n",
    "            suboptimal_arms[z - 1] = suboptimal_arms_count\n",
    "            zeros_counts[z - 1] = zeros_count\n",
    "            ones_counts[z - 1] = ones_count\n",
    "\n",
    "    return {\n",
    "        \"total_rewards\": total_rewards,\n",
    "        \"suboptimal_arms\": suboptimal_arms,\n",
    "        \"regret\": regret,\n",
    "        \"zeros_counts\": zeros_counts,\n",
    "        \"ones_counts\": ones_counts\n",
    "    }\n",
    "\n",
    "def general_simulation(algorithm, arm_means, parameters, strategy_fn):\n",
    "    \"\"\"\n",
    "    Runs a general simulation for the specified bandit algorithm over given parameters and arm means using a provided simulation function.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    parameters : list\n",
    "        A list of parameters (timesteps) for which to record the results.\n",
    "    arm_means : numpy.ndarray\n",
    "        The true means of each arm.\n",
    "    simulation_func : function\n",
    "        The simulation function to run for the algorithm. This function should accept the same parameters as ETC_simulation and return results in a similar format.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    max_time_horizon = max(parameters)\n",
    "    num_arms = len(arm_means)\n",
    "\n",
    "    for iteration in range(1, 101):\n",
    "        results = strategy_fn(arm_means, max_time_horizon)\n",
    "\n",
    "        for param in parameters:\n",
    "            total_reward = results[\"total_rewards\"][param - 1]\n",
    "            suboptimal_arms_count = results[\"suboptimal_arms\"][param - 1]\n",
    "            total_regret = results[\"regret\"][param - 1]\n",
    "            zeros_count = results[\"zeros_counts\"][param - 1]\n",
    "            ones_count = results[\"ones_counts\"][param - 1]\n",
    "\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n",
    "\n",
    "\n",
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"8_UCB-Improved\"),\n",
    "]\n",
    "\n",
    "\n",
    "arm_means = np.array([0.495, 0.5])\n",
    "\n",
    "# Perform simulation and save results\n",
    "results_path = r'C:/Users/canis/OneDrive\\Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "for algorithm in algorithms:\n",
    "    general_simulation(algorithm, arm_means, time_horizons, UCB_Improved_simulation)\n",
    "    algorithm.save_results_to_csv(f'{results_path}\\{algorithm.name}_results_subopt_ver3.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}\\{algorithm.name}_average_results_subopt_ver3.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
