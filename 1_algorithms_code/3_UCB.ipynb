{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "class BanditAlgorithm:\n",
    "    \"\"\"\n",
    "    A class to represent a bandit algorithm and manage its results.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    name : str\n",
    "        The name of the bandit algorithm.\n",
    "    results : list\n",
    "        A list to store results of the algorithm's performance over iterations.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, timestep, iteration, total_reward, suboptimal_arms, total_regret, zeros_count, ones_count):\n",
    "        self.results.append((timestep, iteration, total_reward, suboptimal_arms, round(total_regret, 2), np.sum(zeros_count), np.sum(ones_count)))\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        self.results.sort(key=lambda x: (x[1], x[0]))\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        time_steps = sorted(set(result[0] for result in self.results))\n",
    "        avg_results = []\n",
    "        for timestep in time_steps:\n",
    "            total_reward_sum = 0\n",
    "            suboptimal_arms_sum = 0\n",
    "            regret_sum = 0\n",
    "            zeros_count_sum = 0\n",
    "            ones_count_sum = 0\n",
    "            count = 0\n",
    "            for result in self.results:\n",
    "                if result[0] == timestep:\n",
    "                    total_reward_sum += result[2]\n",
    "                    suboptimal_arms_sum += result[3]\n",
    "                    regret_sum += result[4]\n",
    "                    zeros_count_sum += result[5]\n",
    "                    ones_count_sum += result[6]\n",
    "                    count += 1\n",
    "            avg_total_reward = total_reward_sum / count if count > 0 else 0\n",
    "            avg_suboptimal_arms = suboptimal_arms_sum / count if count > 0 else 0\n",
    "            avg_regret = regret_sum / count if count > 0 else 0\n",
    "            avg_zeros_count = zeros_count_sum / count if count > 0 else 0\n",
    "            avg_ones_count = ones_count_sum / count if count > 0 else 0\n",
    "            avg_results.append((timestep, avg_total_reward, avg_suboptimal_arms, avg_regret, avg_zeros_count, avg_ones_count))\n",
    "        return avg_results\n",
    "\n",
    "def general_simulation(algorithm, arm_means, parameters, strategy_fn, **kwargs):\n",
    "    \"\"\"\n",
    "    Runs a general simulation for the specified bandit algorithm over given parameters and arm means using a provided simulation function.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    parameters : list\n",
    "        A list of parameters (timesteps) for which to record the results.\n",
    "    arm_means : numpy.ndarray\n",
    "        The true means of each arm.\n",
    "    simulation_func : function\n",
    "        The simulation function to run for the algorithm. This function should accept the same parameters as ETC_simulation and return results in a similar format.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    max_time_horizon = max(parameters)\n",
    "    num_arms = len(arm_means)\n",
    "    \n",
    "    for iteration in range(1, 101):\n",
    "        results = strategy_fn(arm_means, num_arms, max_time_horizon, **kwargs)\n",
    "        \n",
    "        for param in parameters:\n",
    "            total_reward = np.sum(results[\"rewards\"][:param])\n",
    "            suboptimal_arms_count = np.sum(results[\"suboptimal_arms\"][:param])\n",
    "            total_regret = np.sum(results[\"regret\"][:param])\n",
    "            zeros_count = np.sum(results[\"zeros_count\"][:param])\n",
    "            ones_count = np.sum(results[\"ones_count\"][:param])\n",
    "            \n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n",
    "\n",
    "\n",
    "class UCB1:\n",
    "    def __init__(self):\n",
    "        self.counts = []\n",
    "        self.values = []\n",
    "\n",
    "\n",
    "    def initialize(self, n_arms):\n",
    "        self.counts = [0] * n_arms\n",
    "        self.values = [0.0] * n_arms\n",
    "\n",
    "    def select_arm(self):\n",
    "        n_arms = len(self.counts)\n",
    "        for arm in range(n_arms):\n",
    "            if self.counts[arm] == 0:\n",
    "                return arm\n",
    "\n",
    "        total_counts = sum(self.counts)\n",
    "        ucb_values = [0.0] * n_arms\n",
    "\n",
    "        for arm in range(n_arms):\n",
    "            bonus = math.sqrt((2 * math.log(total_counts)) / self.counts[arm])\n",
    "            ucb_values[arm] = self.values[arm] + bonus\n",
    "\n",
    "        return ucb_values.index(max(ucb_values))\n",
    "\n",
    "    def update(self, chosen_arm, reward):\n",
    "        self.counts[chosen_arm] += 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        new_value = ((n - 1) / n) * value + (1 / n) * reward\n",
    "        self.values[chosen_arm] = new_value\n",
    "\n",
    "def UCB_simulation(arm_means, num_arms, total_steps):\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates the UCB algorithm over given time horizons.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm : BanditAlgorithm\n",
    "        The bandit algorithm instance to store the results.\n",
    "    num_arms : in\n",
    "        The length of the arm_means array.\n",
    "    total_steps : list\n",
    "        A list of time horizons at which to record the results.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary where keys are time horizons and values are tuples of (total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count).\n",
    "    \"\"\"\n",
    "\n",
    "    ucb = UCB1()\n",
    "    ucb.initialize(num_arms)\n",
    "    regret = np.zeros(total_steps)\n",
    "    total_regret = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    rewards = np.zeros(total_steps)\n",
    "    suboptimal_arms = np.zeros(total_steps, dtype=int)\n",
    "    regret = np.zeros(total_steps)\n",
    "    zeros_count = np.zeros(total_steps, dtype=int)\n",
    "    ones_count = np.zeros(total_steps, dtype=int)\n",
    "\n",
    "    for t in range(total_steps):\n",
    "        chosen_arm = ucb.select_arm()\n",
    "        reward = np.random.binomial(1, arm_means[chosen_arm])\n",
    "        total_reward += reward\n",
    "        ucb.update(chosen_arm, reward)\n",
    "        total_regret += regret[t]\n",
    "        rewards[t] = reward\n",
    "        regret[t] = np.max(arm_means) - arm_means[chosen_arm]\n",
    "        if chosen_arm != np.argmax(arm_means):\n",
    "            suboptimal_arms[t] = 1\n",
    "        if reward == 0:\n",
    "            zeros_count[t] = 1\n",
    "        else:\n",
    "            ones_count[t] = 1\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"rewards\": rewards,\n",
    "        \"suboptimal_arms\": suboptimal_arms,\n",
    "        \"regret\": regret,\n",
    "        \"zeros_count\": zeros_count,\n",
    "        \"ones_count\": ones_count\n",
    "    }\n",
    "\n",
    "\n",
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"3_UCB\"),\n",
    "]\n",
    "\n",
    "arm_means = np.array([0.9, 0.8]) \n",
    "\n",
    "# Perform simulation and save results\n",
    "results_path = r'C:/Users/canis/OneDrive/Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "for algorithm in algorithms:\n",
    "    general_simulation(algorithm, arm_means, time_horizons, UCB_simulation)\n",
    "    algorithm.save_results_to_csv(f'{results_path}/{algorithm.name}_results_opt_ver1.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}/{algorithm.name}_average_results_opt_ver1.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
