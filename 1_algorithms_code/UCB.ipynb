{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class BanditAlgorithm: Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAlgorithm:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, timestep, iteration, total_reward, suboptimal_arms, regret, zeros_count, ones_count):\n",
    "        self.results.append((timestep, iteration, total_reward, suboptimal_arms, regret, zeros_count, ones_count))\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        self.results.sort(key=lambda x: (x[1], x[0]))\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                timestep = result[0]\n",
    "                iteration = result[1]\n",
    "                zeros_counts = sum(result[5])  # Summiere alle Nullen\n",
    "                ones_counts = sum(result[6])   # Summiere alle Einsen\n",
    "                writer.writerow([timestep, iteration, *result[2:5], zeros_counts, ones_counts])\n",
    "\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        time_steps = sorted(set(result[0] for result in self.results))\n",
    "        avg_results = []\n",
    "        for timestep in time_steps:\n",
    "            total_reward_sum = 0\n",
    "            suboptimal_arms_sum = 0\n",
    "            regret_sum = 0\n",
    "            zeros_count_sum = 0\n",
    "            ones_count_sum = 0\n",
    "            count = 0\n",
    "            for result in self.results:\n",
    "                if result[0] == timestep:\n",
    "                    total_reward_sum += result[2]\n",
    "                    suboptimal_arms_sum += result[3]\n",
    "                    regret_sum += result[4]\n",
    "                    zeros_count_sum += sum(result[5])  # Summiere alle Nullen in der Liste\n",
    "                    ones_count_sum += sum(result[6])   # Summiere alle Einsen in der Liste\n",
    "                    count += 1\n",
    "            avg_total_reward = total_reward_sum / count if count > 0 else 0\n",
    "            avg_suboptimal_arms = suboptimal_arms_sum / count if count > 0 else 0\n",
    "            avg_regret = regret_sum / count if count > 0 else 0\n",
    "            avg_zeros_count = zeros_count_sum / count if count > 0 else 0\n",
    "            avg_ones_count = ones_count_sum / count if count > 0 else 0\n",
    "            avg_results.append((timestep, avg_total_reward, avg_suboptimal_arms, avg_regret, avg_zeros_count, avg_ones_count))\n",
    "        return avg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB1:\n",
    "    def __init__(self):\n",
    "        self.counts = []\n",
    "        self.values = []\n",
    "        self.zeros_counts = []\n",
    "        self.ones_counts = []\n",
    "        \n",
    "    def initialize(self, n_arms):\n",
    "        self.counts = [0] * n_arms\n",
    "        self.values = [0.0] * n_arms\n",
    "        self.zeros_counts = [0] * n_arms\n",
    "        self.ones_counts = [0] * n_arms\n",
    "    \n",
    "    def select_arm(self):\n",
    "        n_arms = len(self.counts)\n",
    "        for arm in range(n_arms):\n",
    "            if self.counts[arm] == 0:\n",
    "                return arm\n",
    "        \n",
    "        total_counts = sum(self.counts)\n",
    "        ucb_values = [0.0] * n_arms\n",
    "        \n",
    "        for arm in range(n_arms):\n",
    "            bonus = math.sqrt((2 * math.log(total_counts)) / self.counts[arm])\n",
    "            ucb_values[arm] = self.values[arm] + bonus\n",
    "        \n",
    "        return ucb_values.index(max(ucb_values))\n",
    "    \n",
    "    def update(self, chosen_arm, reward):\n",
    "        self.counts[chosen_arm] += 1\n",
    "        n = self.counts[chosen_arm]\n",
    "        value = self.values[chosen_arm]\n",
    "        new_value = ((n - 1) / n) * value + (1 / n) * reward\n",
    "        self.values[chosen_arm] = new_value\n",
    "        if reward == 0:\n",
    "            self.zeros_counts[chosen_arm] += 1\n",
    "        else:\n",
    "            self.ones_counts[chosen_arm] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCB_simulation(algorithm, arm_means, total_steps):\n",
    "    num_arms = len(arm_means)\n",
    "    ucb = UCB1()\n",
    "    ucb.initialize(num_arms)\n",
    "    optimal_arm = np.argmax(arm_means)\n",
    "    regret = np.zeros(total_steps)\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(total_steps):\n",
    "        chosen_arm = ucb.select_arm()\n",
    "        reward = np.random.binomial(1, arm_means[chosen_arm])\n",
    "        total_reward += reward\n",
    "        ucb.update(chosen_arm, reward)\n",
    "        regret[t] = arm_means[optimal_arm] - arm_means[chosen_arm]\n",
    "        total_regret += regret[t]\n",
    "        if chosen_arm != optimal_arm:\n",
    "            suboptimal_arms_count += 1\n",
    "\n",
    "    total_regret = round(total_regret, 1)\n",
    "\n",
    "    return total_reward, suboptimal_arms_count, total_regret, ucb.zeros_counts, ucb.ones_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(algorithm, parameters, arm_means):\n",
    "    for iteration in range(1, 101):  # Iteriere über 100 Durchläufe   \n",
    "        for param in parameters:\n",
    "            total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count = UCB_simulation(algorithm, arm_means, param)\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCB for different time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Parameter für die Zeit-Horizonte\n",
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "# Beispiel-Algorithmen\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"UCB\"),\n",
    "]\n",
    "\n",
    "# Beispiel-Mittelwerte der Arme\n",
    "arm_means = np.array([0.9, 0.8])  # Beispiel für die Mittelwerte der Arme\n",
    "\n",
    "# Simulation durchführen und Ergebnisse speichern\n",
    "for algorithm in algorithms:\n",
    "    run_simulation(algorithm, time_horizons, arm_means)\n",
    "    algorithm.save_results_to_csv(algorithm.name + '_results.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(algorithm.name + '_average_results.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier wird deutlich, was bei nah beieinanderliegenden rewards passiert--> auch suboptimale Arme werden häufiger gezogen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
