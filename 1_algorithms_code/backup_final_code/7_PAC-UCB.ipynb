{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAC-UCB Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einige Begründungen: Parameter \n",
    "q: Dieser Parameter steuert, wie stark die Exploration im Verhältnis zur Anzahl der bisherigen Ziehungen eines Arms zunimmt. Ein Wert q>1 bedeutet, dass die Exploration überproportional zur Anzahl der Ziehungen eines Arms zunimmt. Für eine moderate Exploration kann man q auf einen Wert zwischen 1.1 und 2 setzen. Um eine Vergleichbarkeit zu den vorherigen Algorithmen herzustellen und nicht zu aggressiv oder konservativ zu explorieren, wählen wir q=1.5\n",
    "\n",
    "β: Dieser Parameter steht in Verbindung mit der Wahrscheinlichkeit, dass die obere Schranke eingehalten wird. Ein typischer Wert für β könnte in der Größenordnung von 0.1 oder 0.01 liegen. Wir wählen β=0.05, um eine gute Balance zwischen Exploration und Exploitation zu gewährleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class BanditAlgorithm: Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAlgorithm:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count):\n",
    "        self.results.append([param, iteration, total_reward, suboptimal_arms_count, round(total_regret, 2), zeros_count, ones_count])\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms Count', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        avg_results = {}\n",
    "        for result in self.results:\n",
    "            param = result[0]\n",
    "            if param not in avg_results:\n",
    "                avg_results[param] = [0, 0, 0, 0, 0]\n",
    "            avg_results[param][0] += result[2]  # Total Reward\n",
    "            avg_results[param][1] += result[3]  # Suboptimal Arms Count\n",
    "            avg_results[param][2] += result[4]  # Total Regret\n",
    "            avg_results[param][3] += result[5]  # Zeros Count\n",
    "            avg_results[param][4] += result[6]  # Ones Count\n",
    "        \n",
    "        for param in avg_results:\n",
    "            avg_results[param] = [param] + [x / 100 for x in avg_results[param]]\n",
    "        return list(avg_results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition PAC-UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAC_UCB_simulation(algorithm, arm_means, time_horizon, c=1, b=1, q=1.3, beta=0.05):\n",
    "    num_arms = len(arm_means)\n",
    "    rewards = np.zeros(num_arms)\n",
    "    counts = np.zeros(num_arms)\n",
    "    sum_of_squares = np.zeros(num_arms)\n",
    "    total_reward = 0\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    zeros_count = 0\n",
    "    ones_count = 0\n",
    "\n",
    "    for t in range(1, time_horizon + 1):\n",
    "        if any(counts < 0):\n",
    "            arm = np.argmin(counts)\n",
    "        else:\n",
    "            PAC = np.zeros(num_arms)\n",
    "            for k in range(num_arms):\n",
    "                if counts[k] > 0:\n",
    "                    mean_reward = rewards[k] / counts[k]\n",
    "                    exploration = max(np.log(num_arms * (counts[k] ** q) / beta), 2)\n",
    "                    variance = (sum_of_squares[k] - counts[k] * (mean_reward ** 2)) / counts[k]\n",
    "                    PAC[k] = mean_reward + np.sqrt((2 * variance * exploration) / counts[k]) + c * (3 * b * exploration / counts[k])\n",
    "            arm = np.argmax(PAC)\n",
    "        \n",
    "        reward = np.random.binomial(1, arm_means[arm])\n",
    "        counts[arm] += 1\n",
    "        rewards[arm] += reward\n",
    "        sum_of_squares[arm] += reward ** 2\n",
    "        total_reward += reward\n",
    "\n",
    "        if reward == 0:\n",
    "            zeros_count += 1\n",
    "        else:\n",
    "            ones_count += 1\n",
    "\n",
    "        if arm != np.argmax(arm_means):\n",
    "            suboptimal_arms_count += 1\n",
    "            total_regret += np.max(arm_means) - arm_means[arm]\n",
    "\n",
    "    return total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(algorithm, parameters, arm_means):\n",
    "    for iteration in range(1, 101):\n",
    "        for param in parameters:\n",
    "            total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count = PAC_UCB_simulation(algorithm, arm_means, param)\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAC-UCB for different time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "# Beispiel-Algorithmen\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"7_PAC-UCB\"),\n",
    "]\n",
    "\n",
    "# Beispiel-Mittelwerte der Arme\n",
    "arm_means = np.array([0.495, 0.5])\n",
    "\n",
    "# Simulation durchführen und Ergebnisse speichern\n",
    "for algorithm in algorithms:\n",
    "    run_simulation(algorithm, time_horizons, arm_means)\n",
    "    results_path = r'C:/Users/canis/OneDrive\\Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "    algorithm.save_results_to_csv(f'{results_path}\\{algorithm.name}_results_subopt_ver3.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}\\{algorithm.name}_average_results_subopt_ver3.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
