{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epsilon - Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class BanditAlgorithm: Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAlgorithm:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, timestep, iteration, total_reward, suboptimal_arms, total_regret, zeros_count, ones_count):\n",
    "        self.results.append((timestep, iteration, total_reward, suboptimal_arms, round(total_regret, 2), np.sum(zeros_count), np.sum(ones_count)))\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        self.results.sort(key=lambda x: (x[1], x[0]))\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        time_steps = sorted(set(result[0] for result in self.results))\n",
    "        avg_results = []\n",
    "        for timestep in time_steps:\n",
    "            total_reward_sum = 0\n",
    "            suboptimal_arms_sum = 0\n",
    "            regret_sum = 0\n",
    "            zeros_count_sum = 0\n",
    "            ones_count_sum = 0\n",
    "            count = 0\n",
    "            for result in self.results:\n",
    "                if result[0] == timestep:\n",
    "                    total_reward_sum += result[2]\n",
    "                    suboptimal_arms_sum += result[3]\n",
    "                    regret_sum += result[4]\n",
    "                    zeros_count_sum += result[5]\n",
    "                    ones_count_sum += result[6]\n",
    "                    count += 1\n",
    "            avg_total_reward = total_reward_sum / count if count > 0 else 0\n",
    "            avg_suboptimal_arms = suboptimal_arms_sum / count if count > 0 else 0\n",
    "            avg_regret = regret_sum / count if count > 0 else 0\n",
    "            avg_zeros_count = zeros_count_sum / count if count > 0 else 0\n",
    "            avg_ones_count = ones_count_sum / count if count > 0 else 0\n",
    "            avg_results.append((timestep, avg_total_reward, avg_suboptimal_arms, avg_regret, avg_zeros_count, avg_ones_count))\n",
    "        return avg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epsilon-Greedy Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epsilon_greedy(arm_means, num_arms, total_steps, epsilon):\n",
    "    Q = np.zeros(num_arms)\n",
    "    N = np.zeros(num_arms)\n",
    "    total_reward = 0\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    regret = np.zeros(total_steps)\n",
    "    zeros_count = np.zeros(total_steps)\n",
    "    ones_count = np.zeros(total_steps)\n",
    "\n",
    "    for t in range(total_steps):\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Exploration\n",
    "            arm = np.random.choice(num_arms)\n",
    "        else:\n",
    "            # Exploitation\n",
    "            arm = np.argmax(Q)\n",
    "\n",
    "        reward = np.random.binomial(1, arm_means[arm])\n",
    "        total_reward += reward\n",
    "        N[arm] += 1\n",
    "        Q[arm] += (reward - Q[arm]) / N[arm]  # Update Q-value incrementally, calculation is already memory optimized\n",
    "        regret[t] = np.max(arm_means) - arm_means[arm]\n",
    "        total_regret += regret[t]\n",
    "        if arm != np.argmax(arm_means):\n",
    "            suboptimal_arms_count += 1\n",
    "        if reward == 0:\n",
    "            zeros_count[t] += 1\n",
    "        else:\n",
    "            ones_count[t] += 1\n",
    "\n",
    "    total_regret = round(total_regret, 2)\n",
    "\n",
    "    return total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(algorithm, parameters):\n",
    "    arm_means = np.array([0.9, 0.895])  # Example mean rewards of arms\n",
    "    num_arms = len(arm_means)\n",
    "    epsilon = 0.05  # Epsilon value for epsilon-greedy\n",
    "    for iteration in range(1, 101):\n",
    "        for param in parameters:\n",
    "            total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count = epsilon_greedy(arm_means, num_arms, param, epsilon)\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epsilon - greedy for different time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Simulation durchführen und Ergebnisse speichern\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algorithm \u001b[38;5;129;01min\u001b[39;00m algorithms:\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     results_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/canis/OneDrive/Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msave_results_to_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_opt_ver2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mrun_simulation\u001b[1;34m(algorithm, parameters)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m----> 7\u001b[0m         total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count \u001b[38;5;241m=\u001b[39m \u001b[43mepsilon_greedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marm_means\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_arms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         algorithm\u001b[38;5;241m.\u001b[39madd_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36mepsilon_greedy\u001b[1;34m(arm_means, num_arms, total_steps, epsilon)\u001b[0m\n\u001b[0;32m     23\u001b[0m regret[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(arm_means) \u001b[38;5;241m-\u001b[39m arm_means[arm]\n\u001b[0;32m     24\u001b[0m total_regret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m regret[t]\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arm \u001b[38;5;241m!=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43marm_means\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     26\u001b[0m     suboptimal_arms_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\canis\\OneDrive\\Dokumente\\uni\\uni-surface\\FSS 2024\\BA\\bachelorarbeit_vrlfg\\BA\\github\\BA_code\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:1298\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\canis\\OneDrive\\Dokumente\\uni\\uni-surface\\FSS 2024\\BA\\bachelorarbeit_vrlfg\\BA\\github\\BA_code\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"2_Greedy\"),\n",
    "]\n",
    "\n",
    "# Simulation durchführen und Ergebnisse speichern\n",
    "for algorithm in algorithms:\n",
    "    run_simulation(algorithm, time_horizons)\n",
    "    results_path = r'C:/Users/canis/OneDrive/Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "    algorithm.save_results_to_csv(f'{results_path}/{algorithm.name}_results_opt_ver2.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}/{algorithm.name}_average_results_opt_ver2.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
