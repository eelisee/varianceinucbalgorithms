{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore-Then-Commit Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class BanditAlgorithm: Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAlgorithm:\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        Initialisierung\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, timestep, iteration, total_reward, suboptimal_arms, regret, zeros_count, ones_count):\n",
    "        '''\n",
    "        Hinzufügen der Ergebnisse zu Liste\n",
    "        '''\n",
    "        self.results.append((timestep, iteration, total_reward, suboptimal_arms, round(regret, 2), np.sum(zeros_count), np.sum(ones_count)))\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        '''\n",
    "        Hinzufügen der Ergebnisse zu Ausgabe\n",
    "        '''\n",
    "        self.results.sort(key=lambda x: (x[1], x[0]))  # Sortiere die Ergebnisse nach der Iterations-ID und dem Zeitstempel\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Timestep', 'Iteration', 'Total Reward', 'Suboptimal Arms', 'Total Regret', 'Zeros Count', 'Ones Count'])\n",
    "            for result in self.results:\n",
    "                writer.writerow(result)\n",
    "\n",
    "\n",
    "    def calculate_average_results(self):\n",
    "        '''\n",
    "        Berechnung des durchschnittlichen Verlaufs der 100 Versuche des Algorithmus\n",
    "        '''\n",
    "        time_steps = sorted(set(result[0] for result in self.results))\n",
    "        avg_results = []\n",
    "        for timestep in time_steps:\n",
    "            total_reward_sum = 0\n",
    "            suboptimal_arms_sum = 0\n",
    "            regret_sum = 0\n",
    "            zeros_count_sum = 0\n",
    "            ones_count_sum = 0\n",
    "            count = 0\n",
    "            for result in self.results:\n",
    "                if result[0] == timestep:\n",
    "                    total_reward_sum += result[2]\n",
    "                    suboptimal_arms_sum += result[3]\n",
    "                    regret_sum += result[4]\n",
    "                    zeros_count_sum += result[5]\n",
    "                    ones_count_sum += result[6]\n",
    "                    count += 1\n",
    "            avg_total_reward = total_reward_sum / count if count > 0 else 0\n",
    "            avg_suboptimal_arms = suboptimal_arms_sum / count if count > 0 else 0\n",
    "            avg_regret = regret_sum / count if count > 0 else 0\n",
    "            avg_zeros_count = zeros_count_sum / count if count > 0 else 0\n",
    "            avg_ones_count = ones_count_sum / count if count > 0 else 0\n",
    "            avg_results.append((timestep, avg_total_reward, avg_suboptimal_arms, avg_regret, avg_zeros_count, avg_ones_count))\n",
    "        return avg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETC Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_then_commit(arm_means, num_arms, total_steps, m):\n",
    "    '''\n",
    "    ETC Algorithmus:\n",
    "    Input: Arme mit erwartetem Reward, optimaler Arm, Anzahl der Zeitschritte\n",
    "    Output: gesamter Reward nach Ende der Zeitschritte, gezogene Anzahl des suboptimalen Arms, kummuliert Reward Gap als Regret zum jeweiligen Zeitschritt\n",
    "    '''\n",
    "\n",
    "    # Choosing the optimal arm\n",
    "    optimal_arm = np.argmax(arm_means)\n",
    "\n",
    "    # Initialize variables\n",
    "    num_pulls = np.zeros(num_arms)\n",
    "    total_reward = 0\n",
    "    suboptimal_arms_count = 0\n",
    "    total_regret = 0\n",
    "    regret = np.zeros(total_steps)\n",
    "    zeros_count = np.zeros(total_steps)\n",
    "    ones_count = np.zeros(total_steps)\n",
    "\n",
    "    # Exploration Phase: ach arm is pulled once to ensure exploration\n",
    "    for arm in range(num_arms):\n",
    "        reward = np.random.binomial(1, arm_means[arm])\n",
    "        num_pulls[arm] = 1\n",
    "        total_reward += reward\n",
    "        regret[arm] = arm_means[optimal_arm] - arm_means[arm]\n",
    "        total_regret += regret[arm]\n",
    "        if arm != optimal_arm:\n",
    "            suboptimal_arms_count += 1\n",
    "        if reward == 0:\n",
    "            zeros_count[arm] += 1\n",
    "        else:\n",
    "            ones_count[arm] += 1\n",
    "\n",
    "    # Commit /Exploitation Phase\n",
    "    for t in range(num_arms, total_steps):\n",
    "        arm = np.argmax(arm_means)\n",
    "        reward = np.random.binomial(1, arm_means[arm])\n",
    "        num_pulls[arm] += 1\n",
    "        total_reward += reward\n",
    "        regret[t] = arm_means[optimal_arm] - arm_means[arm]\n",
    "        total_regret += regret[t]\n",
    "        if arm != optimal_arm:\n",
    "            suboptimal_arms_count += 1\n",
    "        if reward == 0:\n",
    "            zeros_count[t] += 1\n",
    "        else:\n",
    "            ones_count[t] += 1\n",
    "\n",
    "    total_regret = round(total_regret,2)\n",
    "\n",
    "    return total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(algorithm, parameters):\n",
    "    '''\n",
    "    Wiederholter Aufruf des ETC Algorithmus\n",
    "    '''\n",
    "\n",
    "    arm_means = np.array([0.9, 0.8])  # Beispiel für die Mittelwerte der Arme\n",
    "    num_arms = 2  # Anzahl der Arme\n",
    "    m = num_arms  # Anzahl der Schritte für das Erkunden\n",
    "\n",
    "    for iteration in range(1, 101):  # Iteriere über 100 Durchläufe\n",
    "\n",
    "        for param in parameters:\n",
    "\n",
    "            total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count = explore_then_commit(\n",
    "                arm_means, num_arms, param, m)\n",
    "\n",
    "            # Hinzufügen der Ergebnisse zum Algorithmus-Objekt für alle Parameter\n",
    "            algorithm.add_result(param, iteration, total_reward, suboptimal_arms_count, total_regret, zeros_count, ones_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETC for different time horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Parameter für die Zeit-Horizonte\n",
    "time_horizons = [2, 3, 100, 200, 2000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "\n",
    "# Beispiel-Algorithmen\n",
    "algorithms = [\n",
    "    BanditAlgorithm(\"1_ETC\"),\n",
    "]\n",
    "\n",
    "# Simulation durchführen und Ergebnisse speichern\n",
    "for algorithm in algorithms:\n",
    "    run_simulation(algorithm, time_horizons)\n",
    "    results_path = r'C:/Users/canis/OneDrive/Dokumente/uni/uni-surface/FSS 2024/BA/bachelorarbeit_vrlfg/BA/github/BA_code/2_algorithms_results'\n",
    "    algorithm.save_results_to_csv(f'{results_path}/{algorithm.name}_results_opt_ver1.csv')\n",
    "    avg_results = algorithm.calculate_average_results()\n",
    "    with open(f'{results_path}/{algorithm.name}_average_results_opt_ver1.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestep', 'Average Total Reward', 'Average Suboptimal Arms', 'Average Regret', 'Average Zeros Count', 'Average Ones Count'])\n",
    "        for result in avg_results:\n",
    "            writer.writerow(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
